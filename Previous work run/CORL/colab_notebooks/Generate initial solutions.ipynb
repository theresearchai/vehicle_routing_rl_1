{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Generate initial solutions.ipynb","provenance":[{"file_id":"1Hjfo1lKTHFAHfu6SxCMlpQplSYlKIj4-","timestamp":1601496345167},{"file_id":"1-virH5eoLhntdlzQejTsUsO0undnzkrR","timestamp":1597592301603},{"file_id":"1k6NgvMVYkz07WDXLcS84XulCHmCdV2je","timestamp":1594515484374},{"file_id":"1GkySQlBY9x2Qft9q5ENyLrZerizdfiRq","timestamp":1593300375713}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"qHWBoJA3KA53","executionInfo":{"status":"ok","timestamp":1603488250922,"user_tz":240,"elapsed":690,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}},"outputId":"1057a2ab-a41d-49fd-e56a-ee69d4459a73","colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["# This ensures that a gpu is being used by the current google colab session.\n","# If testing ES, then this block ensures that it is not available\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Fri Oct 23 21:24:10 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    23W / 300W |      0MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zLd2Yfk653Gu","executionInfo":{"status":"ok","timestamp":1603488320262,"user_tz":240,"elapsed":20671,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}},"outputId":"7e2f9d7e-8b96-41d1-f9cf-be231da92307","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# This code block is used to access your google drive\n","\n","from google.colab import drive\n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CwHxwKkL6qh3","executionInfo":{"status":"ok","timestamp":1603488321518,"user_tz":240,"elapsed":506,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}},"outputId":"d7c68f1d-2c7e-4555-8008-0f72cc3bd0d5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Make sure this points to the project folder\n","\n","%cd drive/'My Drive'/CORL"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CORL\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CIuqPr9F0AJ3","executionInfo":{"status":"ok","timestamp":1603488332912,"user_tz":240,"elapsed":545,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}},"outputId":"6ced6002-4b7c-46b0-b114-f4982219618a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd l2i"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CORL/l2i\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"etxLc7djUGod","executionInfo":{"status":"ok","timestamp":1603488359718,"user_tz":240,"elapsed":16004,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}}},"source":["# import projects\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import sys\n","sys.path.insert(0,\"../attention/\")\n","\n","class Config:\n","\n","    def __init__(self):\n","        self.problem_seed = 1\n","        self.test_model = None\n","        self.num_training_points = 100\n","config = Config()\n","\n","import os\n","import numpy as np\n","import torch\n","from torch.utils.data import DataLoader\n","from generate_data import generate_vrp_data\n","from utils import load_model\n","from problems import CVRP\n","from problem import generate_problem\n","import pickle\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"8n5nSxzjDpZk","executionInfo":{"status":"ok","timestamp":1603488369809,"user_tz":240,"elapsed":544,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}}},"source":["# make key for each problem\n","def make_key(problem):\n","  demand = tuple(np.array(problem.capacities[1:])/np.array(problem.capacities[0]))\n","  depot_loc = tuple(problem.locations[0][:2])\n","  locations = tuple(map(tuple, problem.locations[1:,:2]))\n","  return (demand, depot_loc, locations)\n","\n","# convert l2i problem to attention problem\n","def convert_to_attention(problem):\n","  demand = np.array(problem.capacities[1:])/np.array(problem.capacities[0])\n","  depot_loc = problem.locations[0][:2]\n","  locations = problem.locations[1:,:2]\n","\n","  dataset = CVRP.make_dataset(size=100, num_samples=1)\n","  dataset.data = [\n","                  {\n","                      'loc' : torch.tensor(locations, dtype=torch.float32, device=torch.device(device)),\n","                      'demand' : torch.tensor(demand, dtype=torch.float32, device=torch.device(device)),\n","                      'depot' : torch.tensor(depot_loc, dtype=torch.float32, device=torch.device(device))\n","                  }\n","  ]\n","  return dataset\n","\n","# convert attention solution to l2i solution\n","def convert_to_l2i(solution):\n","  solist = solution.tolist()\n","  converted_solution = []\n","  route = [0]\n","  for ele in solist:\n","    route.append(ele)\n","    if not ele:\n","      converted_solution.append(route)\n","      route = [0]\n","  route.append(0)\n","  converted_solution.append(route)\n","  converted_solution.append([0,0])\n","  return converted_solution\n","\n","def use_attention(problem):\n","  # convert to attention problem\n","  att_prob = convert_to_attention(problem)\n","\n","  # Need a dataloader to batch instances\n","  dataloader = DataLoader(att_prob, batch_size=1)\n","\n","  # Make var works for dicts\n","  batch = next(iter(dataloader))\n","\n","  # Run the model\n","  model.eval()\n","  model.set_decode_type('greedy')\n","  with torch.no_grad():\n","    length, log_p, pi = model(batch, return_pi=True)\n","\n","  # convert to l2i solution\n","  solution = convert_to_l2i(pi[0])\n","\n","  return solution"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIdOggMvXnt8","executionInfo":{"status":"ok","timestamp":1603488438758,"user_tz":240,"elapsed":60671,"user":{"displayName":"RONALD NHONDOVA","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBoTLhwhU1VQPEtTS1Zk6M9RIqT9LwKpFYs1RRMQ=s64","userId":"11760324277398742098"}}},"source":["# This block will load the attention-based model and save the solutions\n","# change the load and save locations as needed.\n","\n","load_ = \"../models/att/vrp100_rollout_20201023T092943_5hr-model.pt\"\n","save_ = \"../init_sols/att_5hr_init_sol.pickle\"\n","\n","# load model\n","model = torch.load(load_, map_location=torch.device(device))\n","\n","# Generate problem solution memory and set seed\n","N_ = 200 # samples\n","memory_ = {}\n","config.problem_seed = 1\n","\n","solutions = []\n","for _ in range(N_):\n","    problem = generate_problem(config)\n","    solutions.append(use_attention(problem))\n","pickle.dump(solutions, open(save_, \"wb\"))"],"execution_count":7,"outputs":[]}]}